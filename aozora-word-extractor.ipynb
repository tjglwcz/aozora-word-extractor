{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[dynet] random seed: 1234\n",
      "[dynet] allocating memory: 32MB\n",
      "[dynet] memory allocation done.\n"
     ]
    }
   ],
   "source": [
    "import nagisa\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from janome.tokenizer import Tokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.aozora.gr.jp/cards/000148/files/795_43522.html\"\n",
    "book_source = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(book_source.content, \"html.parser\")\n",
    "book_text = soup.find(\"div\",{\"class\":\"main_text\"}).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = nagisa.extract(book_text, extract_postags='代名詞').words\n",
    "nouns = nagisa.extract(book_text, extract_postags='名詞').words\n",
    "verbs = nagisa.extract(book_text, extract_postags='動詞').words\n",
    "i_adjectives = nagisa.extract(book_text, extract_postags='形容詞').words\n",
    "na_adjectives = nagisa.extract(book_text, extract_postags='形状詞').words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pronouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_base_form(wordlist):\n",
    "    t = Tokenizer()\n",
    "    base_forms = []\n",
    "\n",
    "    for word in wordlist:\n",
    "        tokens = t.tokenize(word)\n",
    "        for token in tokens:\n",
    "            base_forms.append(token.base_form)\n",
    "\n",
    "    return base_forms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = convert_to_base_form(verbs)\n",
    "i_adjectives = convert_to_base_form(i_adjectives)\n",
    "na_adjectives = convert_to_base_form(na_adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = [word for word in verbs if len(word) > 1]\n",
    "i_adjectives = [word for word in i_adjectives if len(word) > 1]\n",
    "na_adjectives = [word for word in na_adjectives if len(word) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Word  Count\n",
      "0      余     20\n",
      "1     子規     18\n",
      "2      画     24\n",
      "3      一     20\n",
      "4     亡友      2\n",
      "..   ...    ...\n",
      "289  真面目      1\n",
      "290   単純      1\n",
      "291  几帳面      1\n",
      "292   多大      1\n",
      "293   雄大      1\n",
      "\n",
      "[294 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "wordlist = pronouns + nouns + verbs + i_adjectives + na_adjectives\n",
    "wordlist = Counter(wordlist)\n",
    "wordlist = pd.DataFrame(wordlist.items(), columns = ['Word', 'Count'])\n",
    "print(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(\"https://jisho.org/api/v1/search/words?keyword=渋紙\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(\"https://jisho.org/api/v1/search/words?keyword=無い\").json()['data'][0]['jlpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_api_request(word):\n",
    "    url = f\"https://jisho.org/api/v1/search/words?keyword={word}\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        time.sleep(1)\n",
    "        return response.json()\n",
    "    except (requests.exceptions.RequestException, requests.exceptions.Timeout):\n",
    "        print(f\"Timeout for word: {word}. Retrying in 5 seconds...\")\n",
    "        time.sleep(5)\n",
    "        return make_api_request(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reading(wordlist):\n",
    "    results = []\n",
    "    for word in wordlist:\n",
    "        response = make_api_request(word)\n",
    "        try:\n",
    "            result = response['data'][0]['japanese'][0]['reading']\n",
    "        except (IndexError, KeyError):\n",
    "            result = \"unknown\"\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jlpt_level(wordlist):\n",
    "    results = []\n",
    "    for word in wordlist:\n",
    "        response = make_api_request(word)\n",
    "        try:\n",
    "            if response['data'][0]['jlpt']:\n",
    "                result = response['data'][0]['jlpt'][0]\n",
    "            else:\n",
    "                result = \"Unknown\"\n",
    "        except (IndexError, KeyError):\n",
    "            result = \"Unknown\"\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i_adjectives)\n",
    "i_adjectives_reading = get_reading(i_adjectives)\n",
    "print(i_adjectives_reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i_adjectives)\n",
    "i_adjectives_level = get_jlpt_level(i_adjectives)\n",
    "print(i_adjectives_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nouns)\n",
    "nouns_level = get_jlpt_level(nouns)\n",
    "print(nouns_level)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
