{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aozora Bunko Vocabulary Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The aim of this project is to create dataframes based on vocabulary from classic Japanese literature available on Aozora Bunko, with relevant JLPT level data to estimate the difficulty of the book. The dataframes will later be used to create visual guides to Japanese literature based on their level of difficulty.\n",
    "\n",
    "[Aozora Bunko](https://www.aozora.gr.jp/) is a digital library that hosts classic Japanese literature in a convenient HTML format.\n",
    "\n",
    "JLPT (Japanese Language Proficiency Test) is an exam offered by the Japan Foundation as a way of evaluating the Japanese proficiency of non-native speakers. There are 5 levels of this test, with N5 being the easiest, and N1 being the hardest. These levels will be a guide for assuming the difficulty of analysed texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "The main libraries used in this project are\n",
    "- Janome - Japanese text processing, such as tokenisation and conjugation\n",
    "- BeautifulSoup - scraping text from HTML files\n",
    "- pandas - data frame creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "from janome.tokenizer import Tokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source text preparation\n",
    "For this project I chose to analyze \"Rashōmon\" by Akutagawa Ryūnosuke. The original text can be accessed via the [link below](https://www.aozora.gr.jp/cards/000879/files/128_15261.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.aozora.gr.jp/cards/000879/files/128_15261.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After assigning the Aozora Bunko link to a variable, I parse the text using BeautifulSoup. I also access the title of the book and the name of the author to name the csv file afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book loaded: 羅生門 by 芥川龍之介\n"
     ]
    }
   ],
   "source": [
    "book_source = requests.get(URL)\n",
    "soup = BeautifulSoup(book_source.content, \"html.parser\")\n",
    "book_text = soup.find(\"div\",{\"class\":\"main_text\"}).get_text()\n",
    "book_title = soup.find(\"h1\").get_text()\n",
    "book_author = soup.find(\"h2\").get_text()\n",
    "file_name = f'{book_author} - {book_title}.csv'\n",
    "print(f'Book loaded: {book_title} by {book_author}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataframe\n",
    "Next, I created a function that tokenises the text and creates an array of words. The function filters the text to retrieve only the most important parts of speech, such as nouns, adjectives and verbs. All words are converted to their base form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wordlist(text):\n",
    "    t = Tokenizer()\n",
    "    wordlist = []\n",
    "\n",
    "    for token in t.tokenize(text):\n",
    "        if \"名詞\" in token.part_of_speech or (token.part_of_speech.startswith(\"動詞\") and not token.part_of_speech.startswith(\"助動詞\")) or \"形容詞\" in token.part_of_speech or \"代名詞\" in token.part_of_speech:\n",
    "            wordlist.append(token.base_form)\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating an array, I use a counter to consolidate the results and provide a number of occurrences of each word in the text. I create a dataframe from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>する</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ゐる</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>下人</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>事</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>云</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>惧</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>人目</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>患</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>雨風</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>九月</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word  Count\n",
       "31    する     78\n",
       "11    ゐる     59\n",
       "5     下人     44\n",
       "2      事     31\n",
       "42     云     30\n",
       "..   ...    ...\n",
       "301    惧      1\n",
       "300   人目      1\n",
       "299    患      1\n",
       "298   雨風      1\n",
       "688   九月      1\n",
       "\n",
       "[689 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = extract_wordlist(book_text)\n",
    "wordlist = Counter(wordlist)\n",
    "wordlist = pd.DataFrame(wordlist.items(), columns = ['Word', 'Count']).sort_values(by = 'Count', ascending = False)\n",
    "wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the table above, Rashōmon consists of 689 unique words. The most common word in the story is the verb する (suru)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Tests\n",
    "To retrieve data on the JLPT level of each word, I use the Jisho API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'status': 200},\n",
       " 'data': [{'slug': '下人',\n",
       "   'is_common': False,\n",
       "   'tags': [],\n",
       "   'jlpt': [],\n",
       "   'japanese': [{'word': '下人', 'reading': 'げにん'}],\n",
       "   'senses': [{'english_definitions': ['low-rank person', 'menial'],\n",
       "     'parts_of_speech': ['Noun'],\n",
       "     'links': [],\n",
       "     'tags': [],\n",
       "     'restrictions': [],\n",
       "     'see_also': [],\n",
       "     'antonyms': [],\n",
       "     'source': [],\n",
       "     'info': []}],\n",
       "   'attribution': {'jmdict': True, 'jmnedict': False, 'dbpedia': False}}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"https://jisho.org/api/v1/search/words?keyword=下人\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the API response above, we can access not only the JLPT level of the word, but also its English definition and furigana spelling. I will not use this data, however, as the janome library is also able to provide the furigana spelling, regardless of whether there is a record in the API for the queried word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jlpt-n5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"https://jisho.org/api/v1/search/words?keyword=聞く\").json()['data'][0]['jlpt'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to hear'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"https://jisho.org/api/v1/search/words?keyword=聞く\").json()['data'][0]['senses'][0]['english_definitions'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Request Functions\n",
    "I decided to split the API request into two separate functions. The Jisho API tends to timeout frequently, so I implemented the make_api_request() function to automatically resend the request each time there was a timeout. The API fetching happens asynchronously to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def make_api_request(word):\n",
    "    url = f\"https://jisho.org/api/v1/search/words?keyword={word}\"\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, timeout = 10) as response:\n",
    "                response.raise_for_status()\n",
    "                return await response.json()\n",
    "    except (aiohttp.ClientError, asyncio.TimeoutError):\n",
    "        print(f\"Timeout for word: {word}. Retrying in 5 seconds...\")\n",
    "        await asyncio.sleep(5)\n",
    "        return await make_api_request(word)\n",
    "    \n",
    "async def get_word_info(wordlist):\n",
    "    readings = []\n",
    "    levels = []\n",
    "    meanings = []\n",
    "    t = Tokenizer()\n",
    "\n",
    "    for word in tqdm(wordlist, desc='Processing'):\n",
    "        response = await make_api_request(word)\n",
    "\n",
    "        tokens = list(t.tokenize(word))\n",
    "\n",
    "        reading = tokens[0].reading\n",
    "        \n",
    "        try:\n",
    "            level = response['data'][0]['jlpt'][-1]\n",
    "        except (IndexError, KeyError):\n",
    "            level = 'unknown'\n",
    "        \n",
    "        try:\n",
    "            meaning = response['data'][0]['senses'][0]['english_definitions'][0]\n",
    "        except (IndexError, KeyError):\n",
    "            meaning = 'unknown'\n",
    "\n",
    "        readings.append(reading)\n",
    "        levels.append(level)\n",
    "        meanings.append(meaning)\n",
    "\n",
    "    return readings, levels, meanings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Request Test\n",
    "After creating the functions, I tested them using a short vocabulary list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Level</th>\n",
       "      <th>Meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>聞く</td>\n",
       "      <td>キク</td>\n",
       "      <td>jlpt-n5</td>\n",
       "      <td>to hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>やる</td>\n",
       "      <td>ヤル</td>\n",
       "      <td>jlpt-n1</td>\n",
       "      <td>to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>掛ける</td>\n",
       "      <td>カケル</td>\n",
       "      <td>jlpt-n5</td>\n",
       "      <td>to hang up (e.g. a coat, a picture on the wall)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word Reading    Level                                          Meaning\n",
       "0   聞く      キク  jlpt-n5                                          to hear\n",
       "1   やる      ヤル  jlpt-n1                                            to do\n",
       "2  掛ける     カケル  jlpt-n5  to hang up (e.g. a coat, a picture on the wall)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testlist = ['聞く', 'やる', '掛ける']\n",
    "testlist_df = pd.DataFrame(testlist, columns = ['Word'])\n",
    "readings, levels, meanings = await get_word_info(testlist_df['Word'])\n",
    "testlist_df['Reading'] = readings\n",
    "testlist_df['Level'] = levels\n",
    "testlist_df['Meaning'] = meanings\n",
    "testlist_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual vocabulary list creation\n",
    "My functions are working correctly and I am now able to populate my Rashōmon data frame with readings, JLPT level information and word meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  60%|██████    | 416/689 [07:01<03:42,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for word: お. Retrying in 5 seconds...\n",
      "Timeout for word: お. Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  78%|███████▊  | 540/689 [09:40<02:15,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for word: 修理. Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  99%|█████████▉| 683/689 [12:21<00:05,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for word: 晩. Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 689/689 [12:42<00:00,  1.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>Reading</th>\n",
       "      <th>JLPT Level</th>\n",
       "      <th>Meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>する</td>\n",
       "      <td>78</td>\n",
       "      <td>スル</td>\n",
       "      <td>jlpt-n5</td>\n",
       "      <td>to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ゐる</td>\n",
       "      <td>59</td>\n",
       "      <td>ヰル</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>下人</td>\n",
       "      <td>44</td>\n",
       "      <td>ゲニン</td>\n",
       "      <td>unknown</td>\n",
       "      <td>low-rank person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>事</td>\n",
       "      <td>31</td>\n",
       "      <td>コト</td>\n",
       "      <td>jlpt-n3</td>\n",
       "      <td>thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>云</td>\n",
       "      <td>30</td>\n",
       "      <td>ウン</td>\n",
       "      <td>jlpt-n5</td>\n",
       "      <td>to say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>惧</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>jlpt-n3</td>\n",
       "      <td>to fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>人目</td>\n",
       "      <td>1</td>\n",
       "      <td>ヒトメ</td>\n",
       "      <td>jlpt-n1</td>\n",
       "      <td>(public) notice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>患</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>jlpt-n3</td>\n",
       "      <td>patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>雨風</td>\n",
       "      <td>1</td>\n",
       "      <td>アメカゼ</td>\n",
       "      <td>unknown</td>\n",
       "      <td>rain and wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>九月</td>\n",
       "      <td>1</td>\n",
       "      <td>クガツ</td>\n",
       "      <td>unknown</td>\n",
       "      <td>September</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word  Count Reading JLPT Level          Meaning\n",
       "31    する     78      スル    jlpt-n5            to do\n",
       "11    ゐる     59      ヰル    unknown          unknown\n",
       "5     下人     44     ゲニン    unknown  low-rank person\n",
       "2      事     31      コト    jlpt-n3            thing\n",
       "42     云     30      ウン    jlpt-n5           to say\n",
       "..   ...    ...     ...        ...              ...\n",
       "301    惧      1       *    jlpt-n3          to fear\n",
       "300   人目      1     ヒトメ    jlpt-n1  (public) notice\n",
       "299    患      1       *    jlpt-n3          patient\n",
       "298   雨風      1    アメカゼ    unknown    rain and wind\n",
       "688   九月      1     クガツ    unknown        September\n",
       "\n",
       "[689 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readings, levels, meanings = await get_word_info(wordlist['Word'])\n",
    "wordlist['Reading'] = readings\n",
    "wordlist['JLPT Level'] = levels\n",
    "wordlist['Meaning'] = meanings\n",
    "wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I can export the list for further visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist.to_csv(f'data/{file_name}', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
